{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolai/dev/constrained_inversion_mrm/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import h5py \n",
    "import json\n",
    "import shutil\n",
    "import time \n",
    "import torch \n",
    "import glob \n",
    "import scipy.io as sio\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "\n",
    "# torch computation device to calculate jacobian via autograd\n",
    "# device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective Inversion: Peak $B_1$ and Energy Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pulse_directory = 'data/sel_20250313_073618'\n",
    "opt_pulse_param_file = os.path.join(opt_pulse_directory, 'params_selective.json')\n",
    "\n",
    "pulse_inds = [0, 1, 2]\n",
    "\n",
    "with open(opt_pulse_param_file,'r') as fid: par = json.load(fid)\n",
    "gamma_bar = par[0]['gamma_bar']\n",
    "dt = par[0]['raster_time']\n",
    "\n",
    "freq_eval = np.linspace(-4000.0, 4000.0, 512, dtype=np.float64)\n",
    "b1_eval = np.linspace(0.0, 2.0, 512, dtype=np.float64)\n",
    "\n",
    "pulses = []\n",
    "tv = []\n",
    "dur = []\n",
    "mz = []\n",
    "mz_eval = []\n",
    "show_optimized_region = []\n",
    "x_corner = []\n",
    "y_corner = []\n",
    "width = []\n",
    "height = []\n",
    "legend_locs = []\n",
    "titles = []\n",
    "\n",
    "for p in range(len(pulse_inds)):\n",
    "\n",
    "    opt_pulse_file = os.path.join(opt_pulse_directory, 'pulse_%03d.h5'%(pulse_inds[p]))\n",
    "\n",
    "    # load optimized pulse and reference HS pulse\n",
    "    with h5py.File(opt_pulse_file, 'r') as F:\n",
    "        rf_opt = np.array(F['rf_opt'], dtype=np.complex128) * 1e6 / gamma_bar # uT\n",
    "        rf_hs = np.array(F['rf_hs'], dtype=np.complex128) * 1e6 / gamma_bar   # uT\n",
    "        mz_hs = np.array(F['mz_hs'], dtype=np.float64)\n",
    "        mz_opt = np.array(F['mz_opt'], dtype=np.float64)\n",
    "        b1_design = np.array(F['b1_scales'], dtype=np.float64) \n",
    "        freq_design = np.array(F['freq_arr'], dtype=np.float64)\n",
    "    dur_opt = rf_opt.size * dt \n",
    "    dur_hs = rf_hs.size * dt \n",
    "\n",
    "    # simulate magnetization \n",
    "    mz_opt_eval = simulate_mz(rf_opt*1e-6*gamma_bar, freq_eval, b1_eval, dt, device=device, return_numpy=True)\n",
    "    mz_hs_eval = simulate_mz(rf_hs*1e-6*gamma_bar, freq_eval, b1_eval, dt, device=device, return_numpy=True)\n",
    "\n",
    "    # HS pulse (only for p = 0 as this will be the same for all pulses)\n",
    "    if p == 0:\n",
    "        pulses.append(rf_hs)\n",
    "        tv.append(1e3*np.arange(0.0, dur_hs, dt, dtype=np.float64))\n",
    "        dur.append(dur_hs)\n",
    "        mz.append(mz_hs) \n",
    "        mz_eval.append(mz_hs_eval) \n",
    "        show_optimized_region.append(0)\n",
    "        x_corner.append(0)\n",
    "        y_corner.append(0)\n",
    "        width.append(0)\n",
    "        height.append(0)\n",
    "        legend_locs.append('upper right')\n",
    "        titles.append('$\\mathrm{HS\\ Pulse\\ (Initial\\ Guess)}$')\n",
    "\n",
    "    pulses.append(rf_opt)\n",
    "    tv.append(1e3*np.arange(0.0, dur_opt, dt, dtype=np.float64))\n",
    "    dur.append(dur_opt)\n",
    "    mz.append(mz_opt) \n",
    "    mz_eval.append(mz_opt_eval) \n",
    "    show_optimized_region.append(1)\n",
    "    x_corner.append(freq_design.min())\n",
    "    y_corner.append(b1_design.min())\n",
    "    width.append(freq_design.max() - freq_design.min())\n",
    "    height.append(b1_design.max() - b1_design.min())\n",
    "    legend_locs.append('upper right')\n",
    "    titles.append('$\\mathrm{%d\\%%\\ HS\\ Power}$'%(100*par[pulse_inds[p]]['max_energy_fraction_of_hs_reference']))\n",
    "\n",
    "num_pulses = len(pulses)\n",
    "\n",
    "eval_file = os.path.join(opt_pulse_directory, 'eval_data.h5')\n",
    "with h5py.File(eval_file,'w') as F:\n",
    "    F.create_dataset('num_pulses', data=num_pulses)\n",
    "    F.create_dataset('b1_design', data=b1_design)\n",
    "    F.create_dataset('freq_design', data=freq_design)\n",
    "    F.create_dataset('b1_eval', data=b1_eval)\n",
    "    F.create_dataset('freq_eval', data=freq_eval)\n",
    "    for p in range(len(pulses)):\n",
    "        F.create_dataset('pulse_%i'%(p), data=pulses[p]) \n",
    "        F.create_dataset('tv_%i'%(p), data=tv[p])\n",
    "        F.create_dataset('dur_%i'%(p), data=dur[p]*1e3)\n",
    "        F.create_dataset('mz_%i'%(p), data=mz[p])\n",
    "        F.create_dataset('mz_eval_%i'%(p), data=mz_eval[p])\n",
    "        F.create_dataset('show_optimized_region_%i'%(p), data=show_optimized_region[p]) \n",
    "        F.create_dataset('x_corner_%i'%(p), data=x_corner[p]) \n",
    "        F.create_dataset('y_corner_%i'%(p), data=y_corner[p]) \n",
    "        F.create_dataset('width_%i'%(p), data=width[p]) \n",
    "        F.create_dataset('height_%i'%(p), data=height[p]) \n",
    "        F.create_dataset('title_%d'%(p), data=titles[p], dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "        F.create_dataset('legend_loc_%d'%(p), data=legend_locs[p], dtype=h5py.string_dtype(encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Selective Inversion w/ Comparison to Graf et. al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS Pulse Median Percent Inversion at 0 Hz: 99.943857\n",
      "HS Pulse Mean Percent Inversion at 0 Hz: 99.936625\n",
      "\n",
      "HS Pulse Median Percent Inversion at 150 Hz: 99.708707\n",
      "HS Pulse Mean Percent Inversion at 150 Hz: 99.701079\n",
      "\n",
      "Graf Pulse Median Percent Inversion at 0 Hz: 99.865082\n",
      "Graf Pulse Mean Percent Inversion at 0 Hz: 99.849125\n",
      "\n",
      "Graf Pulse Median Percent Inversion at 150 Hz: 93.645585\n",
      "Graf Pulse Mean Percent Inversion at 150 Hz: 92.886311\n",
      "\n",
      "Opt Pulse 0 Median Percent Inversion at 0 Hz: 99.991182\n",
      "Opt Pulse 0 Mean Percent Inversion at 0 Hz: 99.978928\n",
      "\n",
      "Opt Pulse 0 Median Percent Inversion at 150 Hz: 99.733861\n",
      "Opt Pulse 0 Mean Percent Inversion at 150 Hz: 99.701423\n",
      "\n",
      "Opt Pulse 1 Median Percent Inversion at 0 Hz: 99.957935\n",
      "Opt Pulse 1 Mean Percent Inversion at 0 Hz: 99.942659\n",
      "\n",
      "Opt Pulse 1 Median Percent Inversion at 150 Hz: 99.526241\n",
      "Opt Pulse 1 Mean Percent Inversion at 150 Hz: 99.404761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_pulse_directory = 'data/nonsel_20250313_163627'\n",
    "opt_pulse_param_file = os.path.join(opt_pulse_directory, 'params_nonsel.json')\n",
    "\n",
    "freq_eval = np.linspace(-1000.0, 1000.0, 512, dtype=np.float64)\n",
    "b1_eval = np.linspace(0.0, 2.0, 512, dtype=np.float64)\n",
    "b1_high_res = np.linspace(0.8, 1.2, 256, dtype=np.float64)\n",
    "\n",
    "freq_0_150 = np.array([0.0, 150.0], dtype=np.float64)\n",
    "with open(opt_pulse_param_file,'r') as fid: par = json.load(fid)\n",
    "gamma_bar = par[0]['gamma_bar']\n",
    "dt = par[0]['raster_time']\n",
    "\n",
    "# get reference HS pulse\n",
    "opt_pulse_file = os.path.join(opt_pulse_directory, 'pulse_000.h5')\n",
    "with h5py.File(opt_pulse_file, 'r') as F:\n",
    "    rf_hs = np.array(F['rf_hs'], dtype=np.complex128) * 1e6 / gamma_bar   # uT\n",
    "    mz_hs = np.array(F['mz_hs'], dtype=np.float64)\n",
    "    b1_design = np.array(F['b1_scales'], dtype=np.float64) \n",
    "    freq_design = np.array(F['freq_arr'], dtype=np.float64)\n",
    "dur_hs = rf_hs.size * dt \n",
    "mz_hs_eval = simulate_mz(rf_hs*1e-6*gamma_bar, freq_eval, b1_eval, dt, device=device, return_numpy=True)\n",
    "tv_hs = 1e3 * np.arange(0, dur_hs, dt, dtype=np.float64)\n",
    "mz_hs_calc = simulate_mz(rf_hs*1e-6*gamma_bar, freq_0_150, b1_high_res, dt, device=device, return_numpy=True)\n",
    "print('HS Pulse Median Percent Inversion at 0 Hz: %f'%(100*np.median((1-mz_hs_calc[0,:])/2)))\n",
    "print('HS Pulse Mean Percent Inversion at 0 Hz: %f\\n'%(100*np.mean((1-mz_hs_calc[0,:])/2)))\n",
    "print('HS Pulse Median Percent Inversion at 150 Hz: %f'%(100*np.median((1-mz_hs_calc[1,:])/2)))\n",
    "print('HS Pulse Mean Percent Inversion at 150 Hz: %f\\n'%(100*np.mean((1-mz_hs_calc[1,:])/2)))\n",
    "\n",
    "# load the pulse provided by Graf et al\n",
    "graf_pulse_file = 'data/pulse_graf_et_al.mat'\n",
    "df = sio.loadmat(graf_pulse_file)\n",
    "u = np.squeeze(df['u']).astype(np.float64)\n",
    "v = np.squeeze(df['v']).astype(np.float64)\n",
    "rf_graf = (u + 1j*v) * 1e3 # uT\n",
    "dt_graf = 0.01*1e-3\n",
    "dur_graf = rf_graf.size * dt_graf\n",
    "mz_graf = simulate_mz(rf_graf*1e-6*gamma_bar, freq_design, b1_design, dt_graf, device=device, return_numpy=True)\n",
    "mz_graf_eval = simulate_mz(rf_graf*1e-6*gamma_bar, freq_eval, b1_eval, dt_graf, device=device, return_numpy=True)\n",
    "tv_graf = 1e3 * np.arange(0, dur_graf, dt_graf, dtype=np.float64)\n",
    "mz_graf_calc = simulate_mz(rf_graf*1e-6*gamma_bar, freq_0_150, b1_high_res, dt_graf, device=device, return_numpy=True)\n",
    "print('Graf Pulse Median Percent Inversion at 0 Hz: %f'%(100*np.median((1-mz_graf_calc[0,:])/2)))\n",
    "print('Graf Pulse Mean Percent Inversion at 0 Hz: %f\\n'%(100*np.mean((1-mz_graf_calc[0,:])/2)))\n",
    "print('Graf Pulse Median Percent Inversion at 150 Hz: %f'%(100*np.median((1-mz_graf_calc[1,:])/2)))\n",
    "print('Graf Pulse Mean Percent Inversion at 150 Hz: %f\\n'%(100*np.mean((1-mz_graf_calc[1,:])/2)))\n",
    "\n",
    "pulses = [rf_hs, rf_graf]\n",
    "tv = [tv_hs, tv_graf]\n",
    "dur = [dur_hs, dur_graf] # scalar\n",
    "mz = [mz_hs, mz_graf]\n",
    "mz_eval = [mz_hs_eval, mz_graf_eval]\n",
    "show_optimized_region = [0, 1]\n",
    "x_corner = [0, 0.0]\n",
    "y_corner = [0, 0.7] # value of 0.7 hard-coded from Graf et. al.\n",
    "width = [0, 0.0]\n",
    "height = [0, 1.3 - 0.7]\n",
    "legend_locs = ['upper right', 'lower right']\n",
    "titles = ['$\\mathrm{HS\\ Reference}$', '$\\mathrm{Graf\\ et.\\ al.\\ (optim\\ }B_1^+\\mathrm{)}$']\n",
    "\n",
    "opt_files = glob.glob(os.path.join(opt_pulse_directory, 'pulse_*.h5'))\n",
    "for idx, opt_pulse_file in enumerate(opt_files):\n",
    "    with h5py.File(opt_pulse_file, 'r') as F:\n",
    "        rf_opt = np.array(F['rf_opt'], dtype=np.complex128) * 1e6 / gamma_bar # uT\n",
    "        mz_opt = np.array(F['mz_opt'], dtype=np.float64)\n",
    "    dur_opt = rf_opt.size * dt \n",
    "    mz_opt_eval = simulate_mz(rf_opt*1e-6*gamma_bar, freq_eval, b1_eval, dt, device=device, return_numpy=True)\n",
    "    tv_opt = 1e3 * np.arange(0, dur_opt, dt, dtype=np.float64)\n",
    "    mz_opt_calc = simulate_mz(rf_opt*1e-6*gamma_bar, freq_0_150, b1_high_res, dt, device=device, return_numpy=True)\n",
    "    print('Opt Pulse %d Median Percent Inversion at 0 Hz: %f'%(idx, 100*np.median((1-mz_opt_calc[0,:])/2)))\n",
    "    print('Opt Pulse %d Mean Percent Inversion at 0 Hz: %f\\n'%(idx, 100*np.mean((1-mz_opt_calc[0,:])/2)))\n",
    "    print('Opt Pulse %d Median Percent Inversion at 150 Hz: %f'%(idx, 100*np.median((1-mz_opt_calc[1,:])/2)))\n",
    "    print('Opt Pulse %d Mean Percent Inversion at 150 Hz: %f\\n'%(idx, 100*np.mean((1-mz_opt_calc[1,:])/2)))\n",
    "\n",
    "    \n",
    "    pulses.append(rf_opt)\n",
    "    tv.append(tv_opt)\n",
    "    dur.append(dur_opt)\n",
    "    mz.append(mz_opt)\n",
    "    mz_eval.append(mz_opt_eval)\n",
    "    show_optimized_region.append(1)\n",
    "    x_corner.append(freq_design.min())\n",
    "    y_corner.append(b1_design.min())\n",
    "    width.append(freq_design.max() - freq_design.min())\n",
    "    height.append(b1_design.max() - b1_design.min())\n",
    "    legend_locs.append('center')\n",
    "    if par[idx]['max_energy_hz_squared_sec'] is None:\n",
    "        titles.append('$\\mathrm{Proposed\\ 1}$\\n$\\mathrm{(Unconstrained\\ Power)}$')\n",
    "    else:\n",
    "        E_graf = np.sum(np.abs(rf_graf*np.conj(rf_graf))*dt_graf)\n",
    "        E_opt = np.sum(np.abs(rf_opt*np.conj(rf_opt))*dt)\n",
    "        pct_red = int(100 * E_opt / E_graf)\n",
    "        titles.append('$\\mathrm{Proposed\\ 2}$\\n$\\mathrm{(%d\\%%\\ Graf\\ et.\\ al.\\ Power)}$'%(pct_red))\n",
    "\n",
    "\n",
    "eval_file = os.path.join(opt_pulse_directory, 'eval_data.h5')\n",
    "with h5py.File(eval_file,'w') as F:\n",
    "    F.create_dataset('num_pulses', data=num_pulses)\n",
    "    F.create_dataset('b1_design', data=b1_design)\n",
    "    F.create_dataset('freq_design', data=freq_design)\n",
    "    F.create_dataset('b1_eval', data=b1_eval)\n",
    "    F.create_dataset('freq_eval', data=freq_eval)\n",
    "    for p in range(len(pulses)):\n",
    "        F.create_dataset('pulse_%i'%(p), data=pulses[p]) \n",
    "        F.create_dataset('tv_%i'%(p), data=tv[p])\n",
    "        F.create_dataset('dur_%i'%(p), data=dur[p]*1e3)\n",
    "        F.create_dataset('mz_%i'%(p), data=mz[p])\n",
    "        F.create_dataset('mz_eval_%i'%(p), data=mz_eval[p])\n",
    "        F.create_dataset('show_optimized_region_%i'%(p), data=show_optimized_region[p]) \n",
    "        F.create_dataset('x_corner_%i'%(p), data=x_corner[p]) \n",
    "        F.create_dataset('y_corner_%i'%(p), data=y_corner[p]) \n",
    "        F.create_dataset('width_%i'%(p), data=width[p]) \n",
    "        F.create_dataset('height_%i'%(p), data=height[p]) \n",
    "        F.create_dataset('title_%d'%(p), data=titles[p], dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "        F.create_dataset('legend_loc_%d'%(p), data=legend_locs[p], dtype=h5py.string_dtype(encoding='utf-8'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Non-Selective Pulses for Validation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_pulse_directory = 'data/nonsel_20250313_163627'\n",
    "opt_pulse_param_file = os.path.join(opt_pulse_directory, 'params_nonsel.json')\n",
    "\n",
    "with open(opt_pulse_param_file,'r') as fid: par = json.load(fid)\n",
    "gamma_bar = par[0]['gamma_bar']\n",
    "dt = par[0]['raster_time']\n",
    "\n",
    "for n in range(2):\n",
    "    opt_pulse_file = os.path.join(opt_pulse_directory, 'pulse_%03d.h5'%(n))\n",
    "    with h5py.File(opt_pulse_file,'r') as F:\n",
    "        rf = np.array(F['rf_opt'], dtype=np.complex128).astype(np.complex64) # in Hz\n",
    "\n",
    "    # calculate nominal flip angle in degrees to achieve desired peak B1\n",
    "    flip_real = np.sum(2*np.pi*np.real(rf)*dt) * 180 / np.pi\n",
    "    flip_imag = np.sum(2*np.pi*np.imag(rf)*dt) * 180 / np.pi\n",
    "    flip = np.sqrt(flip_real**2 + flip_imag**2)\n",
    "\n",
    "    # save the waveform, dwell time, and nominal flip angle to file \n",
    "    out_file = os.path.join(opt_pulse_directory, 'pulseq_pulse_%03d.h5'%(n))\n",
    "    with h5py.File(out_file,'w') as F:\n",
    "        F.create_dataset('wav', data=rf)\n",
    "        F.create_dataset('dt', data=dt)\n",
    "        F.create_dataset('flip', data=flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Simulations with Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:43<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data/measurements_20250319'\n",
    "data_file = os.path.join(data_folder, 'measured_inversion_factors_with_B0_B1.h5')\n",
    "\n",
    "# load measured data  \n",
    "with h5py.File(data_file,'r') as F:\n",
    "    B0 = np.array(F['B0'], dtype=np.float32).astype(np.float64)\n",
    "    B1 = np.array(F['B1'], dtype=np.float32).astype(np.float64)\n",
    "    img = np.array(F['img'], dtype=np.complex64).astype(np.complex128)\n",
    "    mask = np.array(F['mask'], dtype=np.float32).astype(np.float64)\n",
    "    inv_scales = np.array(F['inv_scales'], dtype=np.float32).astype(np.float64)\n",
    "\n",
    "# calculate inversion factor (Equation 4)\n",
    "IF = 1.0 - 0.5 * np.abs(img[:,:,0,None] + img[:,:,1:]) / np.abs(img[:,:,0,None])\n",
    "\n",
    "# load the pulse waveform \n",
    "pulse_file = 'data/nonsel_20250313_163627/pulse_000.h5'\n",
    "param_file = 'data/nonsel_20250313_163627/params_nonsel.json'\n",
    "with open(param_file,'r') as fid: par = json.load(fid)\n",
    "dt = par[0]['raster_time']\n",
    "with h5py.File(pulse_file,'r') as F:\n",
    "    rf = np.array(F['rf_opt'], dtype=np.complex128)\n",
    "\n",
    "# simulate the inversion factor \n",
    "IF_sim = np.zeros_like(IF)\n",
    "for row in tqdm(range(B0.shape[0])):\n",
    "    for col in range(B0.shape[1]):\n",
    "        b0_val = np.array([B0[row,col]], dtype=np.float64)\n",
    "        b1_val = np.array([B1[row,col]], dtype=np.float64)\n",
    "        if mask[row,col] > 0.0:\n",
    "            for scl in range(inv_scales.size):\n",
    "                mz = simulate_mz(rf * inv_scales[scl], b0_val, b1_val, dt, device=device, return_numpy=True)[0,0]\n",
    "                IF_sim[row,col,scl] = (1 - mz)/2 \n",
    "\n",
    "eval_file = os.path.join(data_folder, 'eval_data_meas_vs_sim.h5')\n",
    "with h5py.File(eval_file,'w') as F:\n",
    "    F.create_dataset('B0', data=B0)\n",
    "    F.create_dataset('B1', data=B1)\n",
    "    F.create_dataset('IF', data=IF)\n",
    "    F.create_dataset('IF_sim', data=IF_sim)\n",
    "    F.create_dataset('mask', data=mask)\n",
    "    F.create_dataset('inv_scales', data=inv_scales)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptivemrilab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
